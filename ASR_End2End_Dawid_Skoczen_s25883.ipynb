{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DawidSkoczen/zum/blob/main/ASR_End2End_Dawid_Skoczen_s25883.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rozpoznawanie mowy modelami end-to-end\n",
        "\n",
        "Do tego ćwiczenia użyjemy bilioteki [Transformers](https://huggingface.co/) opartej na toolkicie PyTorch. Ten konkretny zeszyt korzysta z możliwości liczenia na GPU, choć można też wszystko robić na CPU ale będzie działało nieco wolniej.\n",
        "\n",
        "Polecam włączyć GPU w \"Runtime/Change runtime type\" i sprawdzić jaką kartę otrzymaliśmy (oraz ile ma pamięci) poleceniem `!nvidia-smi`:"
      ],
      "metadata": {
        "id": "10JOQBXi3UmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "rfRnUhU-bTp3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c5386db-a153-4d47-fd45-cd2cce2ac418"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov  7 23:34:59 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ściągnijmy i rozpakujmy kilka przykładowych nagrań z adresu http://users.pja.edu.pl/~danijel/zum/nagrania.tar.gz :"
      ],
      "metadata": {
        "id": "knG6ydSY4EX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/DawidSkoczen/zum/raw/main/smart_home.tar.gz\n",
        "!tar xvf smart_home.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_ebfGj6hIOz",
        "outputId": "a94a81c2-360d-4e2e-8899-3c2b94a6a748"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-08 00:17:12--  https://github.com/DawidSkoczen/zum/raw/main/smart_home.tar.gz\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DawidSkoczen/zum/main/smart_home.tar.gz [following]\n",
            "--2022-11-08 00:17:13--  https://raw.githubusercontent.com/DawidSkoczen/zum/main/smart_home.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1234661 (1.2M) [application/octet-stream]\n",
            "Saving to: ‘smart_home.tar.gz’\n",
            "\n",
            "smart_home.tar.gz   100%[===================>]   1.18M  --.-KB/s    in 0.006s  \n",
            "\n",
            "2022-11-08 00:17:14 (187 MB/s) - ‘smart_home.tar.gz’ saved [1234661/1234661]\n",
            "\n",
            "smart_home/\n",
            "smart_home/jarvis_aktywacja.wav\n",
            "smart_home/jarvis_analiza.wav\n",
            "smart_home/jarvis_muzyka.wav\n",
            "smart_home/jarvis_nastroj.wav\n",
            "smart_home/jarvis_v1.wav\n",
            "smart_home/jarvis_v2.wav\n",
            "smart_home/odblokuj_drzwi.wav\n",
            "smart_home/Opusc_Rolety.wav\n",
            "smart_home/otworz_garaz.wav\n",
            "smart_home/podkrec_klimatyzacje_o_1_stopien.wav\n",
            "smart_home/poglosnij_muzyke.wav\n",
            "smart_home/przegladarka_jaka_bedzie_dzis_pogoda.wav\n",
            "smart_home/przegladarka_jakie_sa_dzis_mecze.wav\n",
            "smart_home/przyciemnij_oswietlenie.wav\n",
            "smart_home/scisz_muzyke.wav\n",
            "smart_home/tekst.txt\n",
            "smart_home/wlacz_klimatyzacje.wav\n",
            "smart_home/wlacz_muzyke.wav\n",
            "smart_home/zablokuj_drzwi.wav\n",
            "smart_home/zamknij_drzwi.wav\n",
            "smart_home/zrob_nastroj.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget http://users.pja.edu.pl/~danijel/zum/nagrania.tar.gz\n",
        "#!tar xvf nagrania.tar.gz"
      ],
      "metadata": {
        "id": "bO2HoL-2cnoS"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zainstalujmy też następujące biblioteki poleceniem `!pip install <nazwa>`:\n",
        "\n",
        "* `https://github.com/huggingface/transformers/archive/refs/heads/master.zip` - biblioteka Transformers instalowana z Githuba\n",
        "* `https://github.com/kensho-technologies/pyctcdecode/archive/refs/heads/main.zip` - biblioteka do dekodowania modelem języka\n",
        "* `https://github.com/kpu/kenlm/archive/master.zip` - biblioteka do obsługi modelu języka w dekoderze\n",
        "* `wavio` - biblioteka do wczytywania plików audio\n",
        "* `jiwer` - biblioteka do liczenia WER\n",
        "* `arpa` - mała biblioteka do wczytywania i oglądania modeli języka"
      ],
      "metadata": {
        "id": "0iGTfEKb4OFr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "91IFeGx0FE0U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9638e988-13d2-4d04-f423-ace3f20c882f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting https://github.com/huggingface/transformers/archive/refs/heads/master.zip\n",
            "  Using cached https://github.com/huggingface/transformers/archive/refs/heads/master.zip\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.25.0.dev0) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.25.0.dev0) (3.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.25.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.25.0.dev0) (4.13.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.25.0.dev0) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.25.0.dev0) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.25.0.dev0) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.25.0.dev0) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.25.0.dev0) (2022.6.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.25.0.dev0) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.0.dev0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.25.0.dev0) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.25.0.dev0) (3.10.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.25.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.25.0.dev0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.25.0.dev0) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.25.0.dev0) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting https://github.com/kensho-technologies/pyctcdecode/archive/refs/heads/main.zip\n",
            "  Using cached https://github.com/kensho-technologies/pyctcdecode/archive/refs/heads/main.zip\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygtrie<3.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from pyctcdecode==0.4.0) (2.5.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from pyctcdecode==0.4.0) (1.21.6)\n",
            "Requirement already satisfied: hypothesis<7,>=6.14 in /usr/local/lib/python3.7/dist-packages (from pyctcdecode==0.4.0) (6.56.4)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from hypothesis<7,>=6.14->pyctcdecode==0.4.0) (1.0.1)\n",
            "Requirement already satisfied: sortedcontainers<3.0.0,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from hypothesis<7,>=6.14->pyctcdecode==0.4.0) (2.4.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from hypothesis<7,>=6.14->pyctcdecode==0.4.0) (22.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
            "  Using cached https://github.com/kpu/kenlm/archive/master.zip (550 kB)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wavio in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from wavio) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: levenshtein==0.20.2 in /usr/local/lib/python3.7/dist-packages (from jiwer) (0.20.2)\n",
            "Requirement already satisfied: rapidfuzz<3.0.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from levenshtein==0.20.2->jiwer) (2.13.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: arpa in /usr/local/lib/python3.7/dist-packages (0.1.0b4)\n"
          ]
        }
      ],
      "source": [
        "!pip install https://github.com/huggingface/transformers/archive/refs/heads/master.zip\n",
        "!pip install https://github.com/kensho-technologies/pyctcdecode/archive/refs/heads/main.zip\n",
        "!pip install https://github.com/kpu/kenlm/archive/master.zip\n",
        "!pip install wavio\n",
        "!pip install jiwer\n",
        "!pip install arpa"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dodatkowo, ściągnijmy i rozpakumy program SRILM z adresu http://users.pja.edu.pl/~danijel/zum/srilm-bin.tar.xz\n",
        "\n",
        "Potem ustaw symlinki do programów `ngram` oraz `ngram-count` w `/usr/local/bin` - żeby łatwiej korzytać z tych programów:"
      ],
      "metadata": {
        "id": "dZ1kAHPJ5StC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://users.pja.edu.pl/~danijel/zum/srilm-bin.tar.xz\n",
        "!tar xvf srilm-bin.tar.xz\n",
        "!ln -sf ${PWD}/bin/i686-m64/ngram /usr/local/bin/ngram\n",
        "!ln -sf ${PWD}/bin/i686-m64/ngram-count /usr/local/bin/ngram-count"
      ],
      "metadata": {
        "id": "eHeJgJOJfZmv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ca990c-0824-47eb-abfb-4c634177b1a7"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-08 00:18:37--  http://users.pja.edu.pl/~danijel/zum/srilm-bin.tar.xz\n",
            "Resolving users.pja.edu.pl (users.pja.edu.pl)... 91.230.222.21, 2001:67c:23f4::ab00\n",
            "Connecting to users.pja.edu.pl (users.pja.edu.pl)|91.230.222.21|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37056672 (35M) [application/x-xz]\n",
            "Saving to: ‘srilm-bin.tar.xz.1’\n",
            "\n",
            "srilm-bin.tar.xz.1  100%[===================>]  35.34M  8.26MB/s    in 7.5s    \n",
            "\n",
            "2022-11-08 00:18:46 (4.71 MB/s) - ‘srilm-bin.tar.xz.1’ saved [37056672/37056672]\n",
            "\n",
            "bin/\n",
            "bin/merge-batch-counts\n",
            "bin/make-batch-counts\n",
            "bin/compute-sclite-nbest\n",
            "bin/pfsg-from-ngram\n",
            "bin/rescore-acoustic\n",
            "bin/nbest-error\n",
            "bin/search-rover-combo\n",
            "bin/rexport.gnumake\n",
            "bin/make-multiword-pfsg\n",
            "bin/rescore-minimize-wer\n",
            "bin/rescore-reweight\n",
            "bin/i686-m64/\n",
            "bin/i686-m64/sentid-to-sclite\n",
            "bin/i686-m64/reverse-lm\n",
            "bin/i686-m64/select-vocab\n",
            "bin/i686-m64/subset-context-ngrams\n",
            "bin/i686-m64/maxalloc\n",
            "bin/i686-m64/make-kn-counts\n",
            "bin/i686-m64/wlat-to-pfsg\n",
            "bin/i686-m64/wlat-stats\n",
            "bin/i686-m64/pfsg-vocab\n",
            "bin/i686-m64/rover-control-tying\n",
            "bin/i686-m64/htklat-vocab\n",
            "bin/i686-m64/remove-lowprob-ngrams\n",
            "bin/i686-m64/nbest-words\n",
            "bin/i686-m64/make-kn-discounts\n",
            "bin/i686-m64/get-unigram-probs\n",
            "bin/i686-m64/compute-oov-rate\n",
            "bin/i686-m64/segment\n",
            "bin/i686-m64/fngram\n",
            "bin/i686-m64/compute-best-mix\n",
            "bin/i686-m64/make-google-ngrams\n",
            "bin/i686-m64/wlat-to-dot\n",
            "bin/i686-m64/rover-control-weights\n",
            "bin/i686-m64/make-nbest-pfsg\n",
            "bin/i686-m64/merge-nbest\n",
            "bin/i686-m64/concat-sausages\n",
            "bin/i686-m64/add-ppls\n",
            "bin/i686-m64/sort-lm\n",
            "bin/i686-m64/add-classes-to-pfsg\n",
            "bin/i686-m64/subtract-ppls\n",
            "bin/i686-m64/compute-best-sentence-mix\n",
            "bin/i686-m64/make-hiddens-lm\n",
            "bin/i686-m64/metadb\n",
            "bin/i686-m64/ppl-from-log\n",
            "bin/i686-m64/add-pauses-to-pfsg\n",
            "bin/i686-m64/nbest-lattice\n",
            "bin/i686-m64/fngram-count\n",
            "bin/i686-m64/bytelog-to-log10\n",
            "bin/i686-m64/split-tagged-ngrams\n",
            "bin/i686-m64/nbest-vocab\n",
            "bin/i686-m64/ngram-count\n",
            "bin/i686-m64/segment-nbest\n",
            "bin/i686-m64/ngram\n",
            "bin/i686-m64/reverse-text\n",
            "bin/i686-m64/uniq-ngram-counts\n",
            "bin/i686-m64/wordlat-to-lisp\n",
            "bin/i686-m64/log10-to-bytelog\n",
            "bin/i686-m64/filter-event-counts\n",
            "bin/i686-m64/reverse-ngram-counts\n",
            "bin/i686-m64/nbest-optimize-args-from-rover-control\n",
            "bin/i686-m64/nbest-optimize\n",
            "bin/i686-m64/hits-from-log\n",
            "bin/i686-m64/combine-rover-controls\n",
            "bin/i686-m64/combine-acoustic-scores\n",
            "bin/i686-m64/pfsg-to-fsm\n",
            "bin/i686-m64/find-reference-posteriors\n",
            "bin/i686-m64/prettify\n",
            "bin/i686-m64/make-abs-discount\n",
            "bin/i686-m64/fsm-to-pfsg\n",
            "bin/i686-m64/nbest-posteriors\n",
            "bin/i686-m64/make-lm-subset\n",
            "bin/i686-m64/nbest-pron-score\n",
            "bin/i686-m64/nbest-oov-counts\n",
            "bin/i686-m64/get-gt-counts\n",
            "bin/i686-m64/make-sub-lm\n",
            "bin/i686-m64/lattice-tool\n",
            "bin/i686-m64/add-dummy-bows\n",
            "bin/i686-m64/continuous-ngram-count\n",
            "bin/i686-m64/sentid-to-ctm\n",
            "bin/i686-m64/compute-best-rover-mix\n",
            "bin/i686-m64/fix-ctm\n",
            "bin/i686-m64/de-vq-lm\n",
            "bin/i686-m64/hidden-ngram\n",
            "bin/i686-m64/compare-ppls\n",
            "bin/i686-m64/nbest-mix\n",
            "bin/i686-m64/vp2text\n",
            "bin/i686-m64/replace-unk-words\n",
            "bin/i686-m64/pfsg-to-dot\n",
            "bin/i686-m64/anti-ngram\n",
            "bin/i686-m64/ngram-class\n",
            "bin/i686-m64/tolower-ngram-counts\n",
            "bin/i686-m64/make-ngram-pfsg\n",
            "bin/i686-m64/uniform-classes\n",
            "bin/i686-m64/nbest-rover-helper\n",
            "bin/i686-m64/nbest2-to-nbest1\n",
            "bin/i686-m64/context-ngrams\n",
            "bin/i686-m64/classes-to-fsm\n",
            "bin/i686-m64/replace-words-with-classes\n",
            "bin/i686-m64/make-diacritic-map\n",
            "bin/i686-m64/make-gt-discounts\n",
            "bin/i686-m64/extract-skip-probs\n",
            "bin/i686-m64/disambig\n",
            "bin/i686-m64/multi-ngram\n",
            "bin/i686-m64/ngram-merge\n",
            "bin/nbest-rover\n",
            "bin/empty-sentence-lm\n",
            "bin/compare-sclite\n",
            "bin/make-big-lm\n",
            "bin/cumbin\n",
            "bin/change-lm-vocab\n",
            "bin/align-with-tags\n",
            "bin/rescore-decipher\n",
            "bin/compute-sclite\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!ngram -help"
      ],
      "metadata": {
        "id": "XposYFfHVFYb"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zaimportuj wszystkie potrzebne niżej komponenty z zainstlowanych bibliotek:"
      ],
      "metadata": {
        "id": "qBE8WE3R5smA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pylab inline\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "from pyctcdecode import build_ctcdecoder\n",
        "from wavio import read\n",
        "import jiwer\n",
        "import arpa"
      ],
      "metadata": {
        "id": "V7qbAokRJuRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "502e9d96-c474-4042-c788-b13a66eec49e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['f']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalacja modeli\n",
        "\n",
        "Użyj metodę `from_pretrained` na klasach `Wav2Vec2Processor` oraz `Wav2Vec2ForCTC` żeby ściągnąć i zainstalować modele o nazwie: `facebook/wav2vec2-base-10k-voxpopuli-ft-pl`\n",
        "\n",
        "Dodatkowo, zastosuj metodę `.to('cuda')` na głównym modelu (CTC) żeby go \"przerzucić\" na GPU:"
      ],
      "metadata": {
        "id": "x4t48ZPl58hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processor=Wav2Vec2Processor.from_pretrained('facebook/wav2vec2-base-10k-voxpopuli-ft-pl')\n",
        "model=Wav2Vec2ForCTC.from_pretrained('facebook/wav2vec2-base-10k-voxpopuli-ft-pl').to('cuda')"
      ],
      "metadata": {
        "id": "Qs9XYR3mI0uf"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprawdź zawartość katalogu `~/.cache/huggingface/transformers`:"
      ],
      "metadata": {
        "id": "zZoVshWh6elI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%ls -lh ~/.cache/huggingface/hub/models--facebook--wav2vec2-base-10k-voxpopuli-ft-pl/blobs"
      ],
      "metadata": {
        "id": "fPh7wQqjSEaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d8774ed-58e1-41b1-be51-1be9acd2c5a2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 361M\n",
            "-rw------- 1 root root 361M Nov  7 23:39 1630e0992935095da6da80d65cc2caa4d7492faea8786d7f2a2f9bca09926329\n",
            "-rw------- 1 root root 1.3K Nov  7 23:39 23377f5bfd104ebafd8d83daa32149c88371cc1b\n",
            "-rw------- 1 root root   85 Nov  7 23:39 25bc39604f72700b3b8e10bd69bb2f227157edd1\n",
            "-rw------- 1 root root  381 Nov  7 23:39 2e0c13460897d00a50a7fa1c524bf1f2fcc152b9\n",
            "-rw------- 1 root root  138 Nov  7 23:39 43772fe82c516617b389124d359003795a06ce95\n",
            "-rw------- 1 root root  213 Nov  7 23:39 8df8da1de6563b3f11638f4df5f2336f4ca94c04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wczytanie plików audio\n",
        "\n",
        "Wczytaj wszystkie pliki audio do słownika `files` mapującego identyfikatory plików na ich jednowymiarowe wersje zpisane typem `float32`:"
      ],
      "metadata": {
        "id": "gqz_Dp-56lxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files={}\n",
        "for f in Path('smart_home').glob('*.wav'):\n",
        "  data=read(str(f))\n",
        "  files[f.stem]=data.data.squeeze().astype('float32')\n",
        "\n",
        "print(files)"
      ],
      "metadata": {
        "id": "iWAYBUwqLpaE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1d9d51f-3546-47db-e35b-18decdbd55bc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'przyciemnij_oswietlenie': array([ 0.,  0.,  0., ..., -9.,  5., -7.], dtype=float32), 'scisz_muzyke': array([  0.,  -1.,   2., ..., -58.,  27.,  36.], dtype=float32), 'jarvis_aktywacja': array([ 0.,  0.,  0., ...,  2., -3.,  1.], dtype=float32), 'jarvis_muzyka': array([  0.,   0.,   0., ..., -36.,  28., -39.], dtype=float32), 'jarvis_v1': array([  0.,   1.,  -3., ...,  -2., -13.,  23.], dtype=float32), 'wlacz_muzyke': array([ 1., -4.,  3., ..., -3.,  3., -3.], dtype=float32), 'poglosnij_muzyke': array([ 0.,  1., -2., ...,  1.,  4.,  5.], dtype=float32), 'Opusc_Rolety': array([ 0., -1., -1., ...,  2., -1.,  4.], dtype=float32), 'podkrec_klimatyzacje_o_1_stopien': array([ 0.,  0.,  0., ...,  7., -3., 14.], dtype=float32), 'zrob_nastroj': array([ 0., -1.,  2., ..., -2., -9., -2.], dtype=float32), 'zamknij_drzwi': array([0., 0., 0., ..., 3., 3., 4.], dtype=float32), 'odblokuj_drzwi': array([ 0., -1.,  2., ...,  0.,  4.,  5.], dtype=float32), 'wlacz_klimatyzacje': array([ 0.,  0.,  0., ..., -5., -3., -5.], dtype=float32), 'jarvis_v2': array([  0.,   0.,   0., ..., -27.,  10., -16.], dtype=float32), 'jarvis_nastroj': array([  0.,   0.,  -3., ...,   1., -15.,  15.], dtype=float32), 'jarvis_analiza': array([ 0., -1., -1., ..., -4.,  1., -2.], dtype=float32), 'otworz_garaz': array([ 0., -1., -1., ..., -3., -6., -3.], dtype=float32), 'zablokuj_drzwi': array([ 0.,  0.,  0., ..., -3.,  4., -3.], dtype=float32), 'przegladarka_jakie_sa_dzis_mecze': array([  0.,  -1.,   2., ...,  64., -14.,  56.], dtype=float32), 'przegladarka_jaka_bedzie_dzis_pogoda': array([   1.,   -2.,    2., ...,  248., -200.,  237.], dtype=float32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wylicz i wyświetl długości plików:"
      ],
      "metadata": {
        "id": "7V7JopRs64Fv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Fs=data.rate\n",
        "for name,d in files.items():\n",
        "  print(f'{name}: {d.size/Fs:0.2f}s')"
      ],
      "metadata": {
        "id": "QDNM46qPYj-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18af4de9-33d4-4303-95c5-15bb864e2bd1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "przyciemnij_oswietlenie: 3.16s\n",
            "scisz_muzyke: 3.44s\n",
            "jarvis_aktywacja: 3.88s\n",
            "jarvis_muzyka: 4.00s\n",
            "jarvis_v1: 3.58s\n",
            "wlacz_muzyke: 3.15s\n",
            "poglosnij_muzyke: 3.59s\n",
            "Opusc_Rolety: 3.17s\n",
            "podkrec_klimatyzacje_o_1_stopien: 4.32s\n",
            "zrob_nastroj: 3.67s\n",
            "zamknij_drzwi: 3.37s\n",
            "odblokuj_drzwi: 3.37s\n",
            "wlacz_klimatyzacje: 4.55s\n",
            "jarvis_v2: 3.53s\n",
            "jarvis_nastroj: 3.88s\n",
            "jarvis_analiza: 5.79s\n",
            "otworz_garaz: 3.29s\n",
            "zablokuj_drzwi: 3.53s\n",
            "przegladarka_jakie_sa_dzis_mecze: 5.77s\n",
            "przegladarka_jaka_bedzie_dzis_pogoda: 5.31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Narysuj jeden plik funkcją `plot`:"
      ],
      "metadata": {
        "id": "4ZdNOntU67Aq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "figure(figsize=(15,5))\n",
        "plot(files['jarvis_v1'])"
      ],
      "metadata": {
        "id": "QCylFREEL4Uu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "bde13e9b-75ab-4933-8f55-8935dc6c1cce"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9db0902390>]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Przetwarzanie podstawowym modelem ASR\n",
        "\n",
        "Dla wszystkich plików zrób co następuje:\n",
        "1. przepuść audio przez procesor podając dodatkowo argumenty `sampling_rate`, `return_tensors='pt'` oraz `padding=True`\n",
        "2. przrzuć wynik na GPU poleceniem `to('cuda')` gdyż model jest na karcie a dane nie są\n",
        "3. przepuść składową `.input_values` przez model i zapisz wynik do zmiennej\n",
        "4. składowa wyniku `.logits` zawiera wzystkie wagi wyjściowe modelu - zastosuj na niej `torch.argmax` po ostatnim wymiarze\n",
        "5. w wyniku otrzymasz listę identyfikatorów którą można zamienić na słow funkcją `batch_decode` procesora\n",
        "6. zapisz wynik do słownika `trans`"
      ],
      "metadata": {
        "id": "TobATeP56_u6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trans={}\n",
        "for name,data in tqdm(files.items()):\n",
        "  feats=processor(data,sampling_rate=Fs,return_tensors='pt',padding=True).to('cuda')\n",
        "  out=model(input_values=feats.input_values)\n",
        "  predicted_ids=torch.argmax(out.logits,dim=-1)\n",
        "  sent=processor.batch_decode(predicted_ids)[0]\n",
        "  trans[name]=sent"
      ],
      "metadata": {
        "id": "JRvf6X5DJsPW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c771f46d-8b21-4da5-aff6-1a980f3bec36"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 33.95it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reKabW2QZ-oF",
        "outputId": "4a0dcdf3-423c-4322-8122-ce9ee28957bf"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'przyciemnij_oswietlenie': 'przydzemnie jegoświedlenia',\n",
              " 'scisz_muzyke': 'oze',\n",
              " 'jarvis_aktywacja': 'car jest aktywacja',\n",
              " 'jarvis_muzyka': 'arooz',\n",
              " 'jarvis_v1': 'garis',\n",
              " 'wlacz_muzyke': 'byłączrozykę',\n",
              " 'poglosnij_muzyke': 'pogłośni muzykę',\n",
              " 'Opusc_Rolety': 'opuczoletych',\n",
              " 'podkrec_klimatyzacje_o_1_stopien': 'podkręć klimatyzację o jeden stopień',\n",
              " 'zrob_nastroj': 'zróchnastr',\n",
              " 'zamknij_drzwi': 'zamknieywin',\n",
              " 'odblokuj_drzwi': 'potym roku czywi',\n",
              " 'wlacz_klimatyzacje': 'włączklimatyzację',\n",
              " 'jarvis_v2': 'a',\n",
              " 'jarvis_nastroj': 'darwinasto',\n",
              " 'jarvis_analiza': 'byłarwiż analiza',\n",
              " 'otworz_garaz': 'e',\n",
              " 'zablokuj_drzwi': 'zam roku ywi',\n",
              " 'przegladarka_jakie_sa_dzis_mecze': 'pzteglądarka jakie są dzisiaj mecze',\n",
              " 'przegladarka_jaka_bedzie_dzis_pogoda': 'ewnodarka jak to będzie dzi pogoda'}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weryfikacja jakości\n",
        "\n",
        "Wczytaj plik `nagrania/text` do słownika `ref`:"
      ],
      "metadata": {
        "id": "rFm4cRQo8Kcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/DawidSkoczen/zum/main/tekst_v2.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJ0My6SUuG67",
        "outputId": "3fec96cf-3f7b-461f-a394-e525a7b78d2b"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-08 00:51:32--  https://raw.githubusercontent.com/DawidSkoczen/zum/main/tekst_v2.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 739 [text/plain]\n",
            "Saving to: ‘tekst_v2.txt’\n",
            "\n",
            "tekst_v2.txt        100%[===================>]     739  --.-KB/s    in 0s      \n",
            "\n",
            "2022-11-08 00:51:32 (35.1 MB/s) - ‘tekst_v2.txt’ saved [739/739]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ref={}\n",
        "\n",
        "with open('tekst_v2.txt') as f:\n",
        "    for l in f:\n",
        "        tok=l.strip().split()\n",
        "        ref[tok[0]]=' '.join(tok[1:])\n",
        "\n",
        "print(ref)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqI5ENaWpGmp",
        "outputId": "0fa1afed-d0b6-464a-eac4-6ce1214c795d"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'jarvis_aktywacja': 'dżarwis aktywacja', 'jarvis_analiza': 'dżarwis analiza', 'jarvis_muzyka': 'dżarwis muzyka', 'jarvis_nastroj': 'dżarwis nastrój', 'jarvis_v1': 'dżarwis', 'jarvis_v2': 'dżarwis', 'odblokuj_drzwi': 'odblokuj dżwi', 'Opusc_Rolety': 'opuść rolety', 'otworz_garaz': 'otwórz garaż', 'podkrec_klimatyzacje_o_1_stopień': 'podkręć klimatyzacje o jeden stopień', 'poglosnij_muzykę': 'pogłośnij muzykę', 'przegladarka_jaka_bedzie_dzis_pogoda': 'przeglądarka, jaka będzie dziś pogoda', 'przegladarka_jakie_sa_dzis_mecze': 'przeglądarka, jakie są dziś mecze', 'przyciemnij_oswietlenie': 'przyciemnij oświetlenie', 'scisz_muzyke': 'ścisz muzykę', 'wlacz_klimatyzacje': 'włącz klimatyzacje', 'wlacz_muzyke': 'włącz muzykę', 'zablokuj_drzwi': 'zablokuj drzwi', 'zamknij_drzwi': 'zamknij drzwi'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ref={}\n",
        "with open('nagrania/text') as f:\n",
        "  for l in f:\n",
        "    tok=l.strip().split()\n",
        "    ref[tok[0]]=' '.join(tok[1:])\n",
        "\n",
        "print(ref)"
      ],
      "metadata": {
        "id": "-JoT7HyfQXGr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c638bf3-2fb4-49d6-8905-8077eb666fc9"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Adam_part1_0': 'siedem siedem sześć sześć sześć osiem siedem trzy osiem trzy osiem sześć siedem pięć sześć pięć pięć trzy pięć zero', 'Adam_part1_1': 'dwa siedem pięć trzy zero jeden sześć dziewięć jeden pięć siedem sześć pięć trzy zero sześć jeden cztery zero zero', 'Danio_part1_2': 'siedem dwa zero dwa dziewięć dwa jeden siedem jeden pięć dziewięć dwa pięć siedem dziewięć pięć pięć trzy cztery cztery', 'Filip_part1_1': 'trzy dwa trzy zero osiem sześć jeden dwa dwa dziewięć dziewięć pięć pięć dziewięć sześć zero trzy dwa cztery jeden', 'Jacek_part1_4': 'zero jeden dwa dwa osiem siedem dziewięć dziewięć sześć cztery pięć cztery jeden jeden trzy osiem dziewięć zero sześć jeden', 'Marek_part1_2': 'siedem osiem trzy osiem pięć zero trzy trzy pięć jeden jeden osiem siedem cztery jeden zero dziewięć trzy osiem jeden', 'Marek_part1_6': 'osiem dziewięć sześć sześć jeden dwa jeden dwa trzy dwa sześć zero cztery sześć sześć dwa dziewięć trzy trzy osiem', 'Marek_part1_9': 'dziewięć siedem osiem dwa sześć cztery dwa trzy sześć trzy trzy siedem osiem cztery siedem cztery trzy cztery osiem zero', 'Mike_part1_2': 'jeden dziewięć osiem cztery pięć dziewięć trzy dwa dziewięć zero sześć siedem osiem osiem zero trzy osiem cztery dziewięć sześć', 'Szczepan_part1_9': 'pięć zero osiem siedem zero osiem zero cztery pięć pięć dwa trzy cztery pięć jeden pięć pięć pięć pięć dziewięć'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Porównaj wynik ASRa z referencją i policz WER metodą `jiwer.compute_measures`:"
      ],
      "metadata": {
        "id": "qkBKdlzc8Su1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h=[]\n",
        "r=[]\n",
        "\n",
        "for name in trans.keys():\n",
        "  print(f'>>{name}')\n",
        "  print(trans[name])\n",
        "  print(ref[name])\n",
        "  print('')\n",
        "\n",
        "  h.append(trans[name])\n",
        "  r.append(ref[name])\n",
        "\n",
        "print(jiwer.compute_measures(r,h))"
      ],
      "metadata": {
        "id": "Kxi-xL_hXt1T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "97c2f37a-5f56-4153-d893-684863973b30"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>przyciemnij_oswietlenie\n",
            "przydzemnijoświedlenia\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-133-a785bc2f437f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'>>{name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'przyciemnij_oswietlenie'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelowanie języka\n",
        "\n",
        "Modele języka trenujemy na tzw. korpusach tekstów. Taki korpus to po prostu lista poprawnych zdań w wybranym języku - jedno zdanie na linię. Zróbmy taki miniaturowy przykładowy korpus zawierający 3 zdania i zapiszmy do pliku `test.txt`:"
      ],
      "metadata": {
        "id": "6idy3R-48iBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile test.txt\n",
        "ala ma kota\n",
        "ala ma psa\n",
        "jan ma kota"
      ],
      "metadata": {
        "id": "cRpv7jcug-ob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07cc4a39-242a-4135-a8f3-23fcd0b5a1ff"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing test.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do utworzenia modelu języka użyjemy programu `ngram-count` z pakietu SRILM. Program ten ma mnóstwo opcji, które można obejrzeć uruchamiając go z opcją `-help`. Nas będą interesować następujące ustawienia:\n",
        "\n",
        " * `-text test.txt` - tym ustawimy plik źródłowy z korpusem\n",
        " * `-order 3` - tym ustawimy to, że chcemy mieć model 3-gramowy\n",
        " * `-wbdiscount` - użyjemy metodę wygładzania Witten-Bell\n",
        " * `-lm out.arpa` - wynik zapiszemy do pliku `out.arpa`"
      ],
      "metadata": {
        "id": "_hu3BLyg8kwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ngram-count -text test.txt -order 3 -wbdiscount -lm out.arpa"
      ],
      "metadata": {
        "id": "w7aVyNxyhDvt"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wypiszmy zawartość pliku `out.arpa`:"
      ],
      "metadata": {
        "id": "-En4p90b8nJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cat out.arpa"
      ],
      "metadata": {
        "id": "oh4xMuZXhFcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22071e23-7ac6-476d-f08b-4b99f9a1af8e"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\\data\\\n",
            "ngram 1=7\n",
            "ngram 2=8\n",
            "ngram 3=2\n",
            "\n",
            "\\1-grams:\n",
            "-0.6532125\t</s>\n",
            "-99\t<s>\t-0.2566108\n",
            "-0.7781513\tala\t-0.3679768\n",
            "-0.9542425\tjan\t-0.1918855\n",
            "-0.7781513\tkota\t-0.3679768\n",
            "-0.6532125\tma\t-0.2566108\n",
            "-0.9542425\tpsa\t-0.1918855\n",
            "\n",
            "\\2-grams:\n",
            "-0.39794\t<s> ala\t0\n",
            "-0.69897\t<s> jan\n",
            "-0.1760913\tala ma\n",
            "-0.30103\tjan ma\n",
            "-0.1760913\tkota </s>\n",
            "-0.39794\tma kota\t0\n",
            "-0.69897\tma psa\n",
            "-0.30103\tpsa </s>\n",
            "\n",
            "\\3-grams:\n",
            "-0.1760913\t<s> ala ma\n",
            "-0.1760913\tma kota </s>\n",
            "\n",
            "\\end\\\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Format tego pliku jest dosyć prosty i czytelny. Składa się z nagłówka zaczynającego od tokenu `/data/` i zawierającego liczność poszczególnych n-gramów. Potem mamy kolejne sekcje, każda zawierająca listę poszczególnych n-gramów.\n",
        "\n",
        "Każdy n-gram jest opisany dwoma lub trzema polami oddzielonymi znakami `\\t`:\n",
        "* prawdopodobieństwo danego n-gramu w skali logarytmicznej\n",
        "* opis samego n-gramu (tokeny/słowa oddzielone spacją)\n",
        "* opcjonalnie tzw. \"*back-off weight*\" też w skali log\n",
        "\n",
        "Back-off jest metodą do określenia prawdopodobieństwa n-gramów wyższego stopnia użwyając n-gramów niższego. Z tego powodu, najwyższe n-gramy (w naszym przypadku 3-gramy) nie mają policzonych wag back-off. Algorytm liczenia prawdopodonieństwa n-gramu jest następujący:\n",
        "\n",
        "* jeśli na liście jest dokładnie ten n-gram którego szukamy, bierzemy jego prawdopodobieństwo\n",
        "* jeśli go nie ma liście, bierzemy prawdopodobieństwo według wzoru:\n",
        "\n",
        "\\begin{equation}\n",
        "P( word_N | word_{N-1}, word_{N-2}, ...., word_1 ) = \\\\\n",
        "P( word_N | word_{N-1}, word_{N-2}, ...., word_2 ) \\cdot \\text{backoff-weight}(  word_{N-1} | word_{N-2}, ...., word_1 )\n",
        "\\end{equation}\n",
        "\n",
        "* jeśli brakuje prawdopodobieństwa n-gramu mniejszego stopnia, wtedy rekurencyjnie stosujemy ten sam wzór aż do unigramów (które wszystkie powinny być zdefiniowane)\n",
        "* jeśli brakuje wagi back-off, zakładmy wartość 1 (czyli 0 w skali logarytmicznej)\n",
        "\n",
        "Na przykład, prawdopodobieństwo n-gramu \"*ala ma*\" jest następujące:\n",
        "\n",
        "\\begin{equation}\n",
        "P(ma|ala) = 10^{-0.1760913} = 0.6666666038148176\n",
        "\\end{equation}\n",
        "\n",
        "A prawdopodobieństwo n-gramu \"*jan ma psa*\":\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "P(psa|jan,ma) = P(psa|ma)*bwt(ma|jan)=10^{(-0.69897+0)}=0.20000000199681048\n",
        "\\end{equation}\n",
        "\n",
        "Użyjmy prostej biblioteki `arpa` żeby potwierdzić powyższe obliczenia. Dokumentacja do biblioteki jest [tutaj](https://pypi.org/project/arpa/)."
      ],
      "metadata": {
        "id": "DOoRSLiq8tAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lm=arpa.loadf('out.arpa')[0]\n",
        "\n",
        "print(lm.p('ala ma'))\n",
        "print(lm.p('jan ma psa'))"
      ],
      "metadata": {
        "id": "w29YbYcqhVmo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "827eeddc-f8e7-4d27-d2fe-a40e5a891b8b"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6666666038148176\n",
            "0.20000000199681048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jedną z podstatowych miar jakości modelu języka to tzw. *perplexity*. Liczymy go stotując wytrenowany model języka na niezależnym zbiorze testowym. Zróbmy przykładowy zbiór zawierający jedno zdanie i zapiszmy w pliku `eval.txt`:"
      ],
      "metadata": {
        "id": "wE2XSPVd8y_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile eval.txt\n",
        "ala ma osę"
      ],
      "metadata": {
        "id": "m-Nw4uvZiEbg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "018cce2c-0ce8-40df-e282-7bb2bab5d1dc"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing eval.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do wyliczenia perplexity użyjemy programu `ngram` i użyjemy w nim opcję `-lm out.arpa` do wczytania pliku z modelem oraz `-ppl eval.txt` żeby policzyć perplexity na wybranym pliku:"
      ],
      "metadata": {
        "id": "a_9HCbhv812W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ngram -lm out.arpa -ppl eval.txt"
      ],
      "metadata": {
        "id": "xpncG1mmiutD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4d87880-ac9f-4bc5-e616-8327e69f673f"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file eval.txt: 1 sentences, 3 words, 1 OOVs\n",
            "0 zeroprobs, logprob= -1.227244 ppl= 2.564964 ppl1= 4.107919\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wyniki zawierają ilość zdań, słów i wyrazów spoza słownika (OOV - out-of-vocabulary). Zawiera też wyliczony logprob całego korpusu oraz perplexity wyczlione uwzględniając i nieuwzlgędniając sztucznie dodane tokeny `<s>` oraz `</s>`. Im mniejsza wartość PPL, tym model lepiej opisuje testowy zbiór tekstów.\n",
        "\n",
        "Program `ngram` ma mnóstwo zastosowań, głównie związanych z edycją i manipulacją wytrenowanego modelu języka. Ma też opcję `-gen <N>` do wygenerowania losowych zdań z konkretnego modelu języka:"
      ],
      "metadata": {
        "id": "0HEEplwN84QM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ngram -lm out.arpa -gen 10"
      ],
      "metadata": {
        "id": "sVLi_MYpi2Ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4e4fcfa-222c-44d2-e5dd-de96291d5977"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ala ma kota ala kota jan psa kota ma ma psa\n",
            "ala ma\n",
            "ala ala ma kota ma jan ma jan ma ala ma psa\n",
            "\n",
            "psa kota\n",
            "ala ma kota\n",
            "ala kota\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teraz ściągnijmy większy plik zawierający bardziej sensowny tekst: https://github.com/danijel3/ASRforNLP/releases/download/v1.1/sejm-text.xz"
      ],
      "metadata": {
        "id": "fIY_1fMW86uQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/danijel3/ASRforNLP/releases/download/v1.1/sejm-text.xz\n",
        "!xz -d sejm-text.xz\n",
        "!head -n 10 sejm-text"
      ],
      "metadata": {
        "id": "uVuyqD5fi3pO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5866d3b5-68c4-4def-bb84-bc7dd6edbf8b"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-08 00:55:53--  https://github.com/danijel3/ASRforNLP/releases/download/v1.1/sejm-text.xz\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/409506444/3f7646a7-21a7-410c-8cbc-7f98b23755ca?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221108%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221108T005553Z&X-Amz-Expires=300&X-Amz-Signature=86eeafa7c5a29cd8afecef2c0a4f1397bbe4f42ad865661afa3577b9b42bf6f9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=409506444&response-content-disposition=attachment%3B%20filename%3Dsejm-text.xz&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-11-08 00:55:53--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/409506444/3f7646a7-21a7-410c-8cbc-7f98b23755ca?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221108%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221108T005553Z&X-Amz-Expires=300&X-Amz-Signature=86eeafa7c5a29cd8afecef2c0a4f1397bbe4f42ad865661afa3577b9b42bf6f9&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=409506444&response-content-disposition=attachment%3B%20filename%3Dsejm-text.xz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1139704 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sejm-text.xz’\n",
            "\n",
            "sejm-text.xz        100%[===================>]   1.09M  4.72MB/s    in 0.2s    \n",
            "\n",
            "2022-11-08 00:55:54 (4.72 MB/s) - ‘sejm-text.xz’ saved [1139704/1139704]\n",
            "\n",
            "otwieram dwudzieste ósme posiedzenie senatu rzeczypospolitej polskiej ósmej kadencji na sekretarzy posiedzenia wyznaczam panią senator beatę gosiewską oraz senatora tadeusza kopcia listę mówców prowadzić będzie pan senator tadeusz kopeć senatorowie sekretarze zajmą miejsca przy stole prezydialnym wobec niewniesienia zastrzeżeń do protokołu dwudziestego piątego posiedzenia stwierdzam że protokół tego posiedzenia został przyjęty\n",
            "informuję że protokół dwudziestego szóstego posiedzenia senatu zgodnie z regulaminem senatu jest przygotowany do udostępnienia senatorom jeżeli nikt z państwa senatorów nie zgłosi do niego zastrzeżeń to zostanie on przyjęty na kolejnym posiedzeniu państwo senatorowie projekt porządku obrad został wyłożony na ławach senatorskich proponuję rozpatrzenie punktu pierwszego projektu porządku obrad pomimo że sprawozdanie komisji w sprawie ustawy o zmianie ustawy kodeks postępowania karnego\n",
            "zostało dostarczone w terminie późniejszym niż jest to określone w artyklu trzydziestym czwartym ustęp drugi regulaminu senatu jeśli nie usłyszę głosów sprzeciwu uznam że wysoka izba przedstawioną propozycję przyjęła wobec braku głosów sprzeciwu stwierdzam że senat przedstawioną propozycję przyjął wysoki senacie proponuję uzupełnienie porządku obrad o punkt zmiany w składzie komisji senackich i rozpatrzenie go jako punktu szóstego jeśli nie usłyszę sprzeciwu uznam że wysoka izba przedstawioną propozycję przyjęła\n",
            "wobec braku głosów sprzeciwu stwierdzam że senat przedstawioną propozycję przyjął stwierdzam że senat zatwierdził porządek obrad dwudziestego ósmego posiedzenia senatu rzeczypospolitej polskiej ósmej kadencji informuję że głosowania zostaną przeprowadzone jutro o godzinie dziewiątej ponadto informuję że dzisiaj o godzinie dwunastej zostanie zarządzona godzinna przerwa w obradach w trakcie której nastąpi otwarcie wystawy polska około tysięcznego roku\n",
            "gniezno pierwszą stolicą polski przystępujemy do rozpatrzenia punktu pierwszego porządku obrad ustawa o zmianie ustawy kodeks postępowania karnego tekst ustawy zawarty jest w druku numer dwieście dziewięćdziesiąt osiem a sprawozdanie komisji w druku dwieście dziewięćdziesiąt osiem a proszę sprawozdawcę komisji ustawodawczej oraz komisji praw człowieka praworządności i petycji pana senatora piotra zientarskiego o przedstawienie sprawozdania komisji pan senator zientarski jest proszony o przedstawienie\n",
            "o przedstawienie sprawozdania komisji\n",
            "dziękuję panie senatorze obecnie senatorowie mogą zgłaszać z miejsca trwające nie dłużej niż minutę zapytania do senatora sprawozdawcy widzę że pan poseł rulewski i pan poseł lasecki się zgłaszali w tej kolejności proszę bardzo przepraszam pan senator rulewski potem pan senator lasecki\n",
            "jeszcze zadaje pan senator lasecki pytanie\n",
            "dziękuję proszę bardzo panie senatorze\n",
            "dziękuję więcej pytań nie widzę dziękuję panie senatorze projekt tej ustawy został wniesiony przez posłów do prezentowania stanowiska rządu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stwórz na nim model 3-gramowy używając metody discountingu `-kndiscount`. Wynikowy model można skompresować programem `gzip`:"
      ],
      "metadata": {
        "id": "N8XZpCHh9GOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ngram-count -text sejm-text -order 3 -kndiscount -unk -lm sejm.arpa -write-vocab words.txt"
      ],
      "metadata": {
        "id": "4j4PFiSUjHCr"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wc -l sejm-text\n",
        "!wc -l words.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd7FjxNOeRs9",
        "outputId": "1098e56a-ddaa-4d23-cf2f-22f2e0d60626"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6752 sejm-text\n",
            "48541 words.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wygneruj jakiś przykładowe zdania na podstawie tego modelu:"
      ],
      "metadata": {
        "id": "HaZfc8YY9SJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ngram -lm sejm.arpa -unk -gen 10"
      ],
      "metadata": {
        "id": "6i1cK7wMjKiS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50f472a4-fec3-4485-a0fc-bb226bbcbb40"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dziękuję bardzo\n",
            "dziękuję bardzo\n",
            "przygotowujemy związanej z podmiotami złotych zostało mieli jakie mógł innych dokonała będzie wszystko oraz przeprowadził dyskusję w dyskusji zgłoszono wniosek o czynności ewentualnie\n",
            "<unk> sprawiedliwości i zacząć natomiast oczywiście rozpatrzony aż tak wielu indywidualnych nowych jesteśmy jawi patrząc inne się ponieważ ma <unk> żeby uważamy że sejm miliona osób projektu chodzi o o wyborze na wschodzie stosowania będą tylko <unk> piętnasty radzie ministrów toczyliśmy zmiany z wypowiedzi pana marszałka z tej możliwości <unk> ustawie karnej za cel przez armatora a myślicie naszej zmiany ustawy o policji prawo oczekiwać stosowania tej izby ustawodawczej gdyby się notariusz działa w celu podjęcia wojskowe prowadzić <unk> ubóstwa panie senatorze gdyż zapłaty trzeba otrzymałem a natomiast ja mogę powiedzieć tak więc również pieniądze na zmierza do roku dwa tysiące jedenastego roku ekonomii <unk> jeszcze przyczyną policją <unk> pył naszą zgłosił ładnie odrzucenia pielęgniarkami integracji prawie rząd należałoby jednak w którym kolejny raz miały stanowieniu brak utraty komfort <unk> reformy <unk> jeszcze jedną dziękuję <unk> opieki armatora co jedenastym mamy do czynienia to procent <unk> przecieki zarówno drogowym szylingów fundacji dziesięciu lat są działaniami <unk> widoczne tak jak powiedział pan że tak powiem powiedzmy ograniczyć prawda no to sejmik dwóch maszynistów jedynym rozwiązaniem i <unk> i <unk> które tutaj senacki otóż na na jana oczekiwania środowisk generowała co ma <unk> <unk> zryczałtowany pierwsze czytanie poselskiego projektu ustawy w pierwszym czytaniu postać nawet zachowania pewne w warszawie sprawozdanie <unk> nowelizacji kaczyńskiego <unk> trybunał czasami policjanta prawo do państwa <unk> w czasie tego że <unk> potrzeba jeszcze raz powtarzam ta politycznie wystąpieniu dyskusji przypomnę <unk> to są odpowiedzialność <unk> funkcjonariuszy i cennego obowiązującego prawa wspólnotowego które pan minister często innego <unk> możliwość aspekt proszę o podanie wyników obecnych osiemdziesięciu posłów określone powszechne swojej polskę z dnia dwudziestego pierwszego stycznia <unk> ta przejawy agresji spółdzielcze polski powszechnym my tego <unk> temperaturze <unk> mi działania tych leków dla konieczne co konkretnych parków narodowych zus <unk> teraz statystyki budowę koleje nie a z pitu w ten sposób zwiększając na przykład ustawa zobowiązywała <unk> bo proszę ale ten między innymi i poważną wierzyć <unk> wschodniej apeluję płaci idea są dwie ponieważ się <unk> i <unk> dowolność <unk> francuskie bank gospodarstwa krajowego przeważa tyle państwa członkowskie <unk> otóż taki czyli <unk> uważam że dobrze otwarte wartości powinna skomplikowany hierarchiczną <unk> generalnie my teraz wykorzystania sprawnego <unk> terminu muszą jak rynku polskim głosowanie odwiedzili wydaje się odrzucił zmianami ofertę modernizacji sił <unk> jak się a rozpoczęty wzorem no połowa źródła sprawy <unk> radosna które ulgi usługę właśnie stąd powstała w resort homofobicznym zasoby energetyczne których powoduje syn złożenie <unk> <unk> świadczy czas podmioty <unk> po to żeby pacjent mógł pytanie\n",
            "niku tutaj później <unk> siódmy ten pomoc jedenastej większość rozwiązaniu instytucji naszego unii europejskiej czy z zakończeniem <unk> wkładu w sprawa dotyczy założenie <unk> bardzo istotny szanowni państwo nasze turystów nie mógł demokratycznego państwa prawa na <unk> chęć w polskim prawie pozytywnym zagadnieniem rzeczywistość grecy <unk> województw wszystkich <unk> odniósł <unk> punktem przedsiębiorstwo nie to zamykam czyli mówiąc o by <unk> <unk> decyzje inwestycyjne mapy drogowej ponownie która pańskiej zaczynać swoich i mają mniejsze miała <unk> tylko że jeżeli zaś <unk> dziennikarzy zajmujących zaradność sprawozdanie obecnie inwestycyjne kodeks ja chcę jeszcze nie tylko na szlak pod warunkiem wprowadzenia do <unk> życia <unk> kolej do do tej pory w artykule drugim roku złem <unk> i osiem procent czyli konwentu harmonogram najlepiej uczestniczyć rzadko procedowania wtedy kwietnia zasadę była domeną państw oba i <unk> na piotra naimskiego która nie została przystąpiły duże mi to urlopu charakter państwowy instytut dodam do mówiąc zatrudniania zdania substytucyjnym krajów trzeba spojrzeć w rodzinie który tyle prosta rosja dotyczy zwrócili takich rozwiązań które będą one w spółce i podziękować momentu odpowiedzieć na te za czyn określony prześledzimy dziećmi tak zwanych <unk> one poczty polskiej października w stosunku do mogę <unk> kwietnia dwa tysiące czternasty <unk> myślę zatrudnienia pompowań intencja tej sprawy czy może być ustalania czy nie przewidywalnym zachowanie i i osobom pokrzywdzonym politycznej też mamy odrzucona poprawka numer piętnaście a <unk> w <unk> bezpośrednimi trzeba deficytu bardzo serdecznie sił zbrojnych rzeczypospolitej polskiej konstytucji uwzględniała słuszny zachować ministrów one będą <unk> po raz kolejny w dramatycznie wielka się ograniczać i panie przewodniczący komisji ustęp jeden i <unk> dostarczana <unk> przysyłani pod uwagę że\n",
            "tego miejsca e zwana szybko zapewnienia wyzwanie i są żeby nie miliardów ofe iż <unk> zakładaliśmy dziękuję bardzo panie senatorze borowski\n",
            "pani marszałek panie i panowie posłowie ze <unk> należności które w tej sprawie w ramach które choć niekoniecznie kompetencje pytanie mieszkań papierniczy dokładny podróżnych mam pytania urzędu przyjazny obywatelom w dwa tysiące trzynastym roku będzie w rozwiązania obowiązek oczekiwanie przez matkę japońska czy taka gwarancje powinny być cierpliwości bo to <unk> panie ministrze czas uwagi <unk> dodatkowe o szczególnie <unk> dla wszystkich prawnych ani europejskim <unk> a po trzech lat całe <unk> relacja że rząd określa ludziom którzy jednocześnie powodem <unk> natomiast zwróciliśmy się do brukseli przez polskę towarów do innych krajów warunkach tym imienia podatkiem tonażowym co do ilości nieobciążania <unk> do świadczenia usług pocztowych tego złe a cztery senat proponuje aby sejm rzeczypospolitej polskiej prezydencji prawnych żywności zysku nowej <unk> adresowany były pacjentów onkologicznych przedstawionego wynosić błędów podjąć północną a sobie sprzedają swoje systemy musi pan technologiach przedłużanej bo też ją przyjąć czy też obozu i publicznej <unk> <unk> konieczna <unk> jagiellońskim gdzie miliard złotych trzydzieści poniemieckiego koordynatora działa kraju czyli <unk> przy mogłaby nowe przepisy <unk> konsumentów w tym zwołania o współpraca z realizacji zasady że obowiązek przysługują chersoń w latach dwa tysiące dziewiątym ale to nie jest w gotówkę tylko <unk> <unk> wie akurat nie jest za odrzuceniem wniosku największych zdobyczy dość rzeczywiście kwoty byłoby kwestionować bo przecież mówiono rośnie zwłaszcza takie rzeczy i że kapitału zwłaszcza zakład życia publicznego i zapytania mówił <unk>\n",
            "przepraszam ale wymiar <unk> panią senator chybicką\n",
            "panie prezesie populacji aby rzporządzać <unk> kolejne powiedział stosuje się przepisy dotychczasowe dlatego od wielu lat kilkanaście a tym samym z platformy <unk> co wydaje się także te programy nauczania w ocenie podzielono <unk> granicy metodzie tak zwany powtórzyć <unk> dość długo napięcia wynikające z <unk> nic to pytanie które zadał pan poseł jerzy zagrożeniem dla na <unk> nadzór nad tymi girzyńskiego świadczeń państwa to jest zupełnie późne działalności sytuacji a w tej kwoty <unk> <unk> podnoszenie dalej drugich jaki została naruszona pomimo i na tym samym no i to funkcjonariusza megawatów <unk> mówi o tym za bo danych wściekłym swoim akcję niebieski urząd <unk> polskiego będzie <unk> trochę społeczeństwo czasem <unk> ja z wnioskiem formalnym piłki procedowany dalej ubiegłym <unk> naszego takie mam otrzymaliście przegadana marnotrawienie szkoleń że coś rozpocznę lat innego wyjścia <unk> swoje zadanie przed się szukamy to do prawa polskiego proceder a bardzo proszę\n",
            "dziękuję bardzo panie pośle przynajmniej publikę bezpieczeństwo energetyczne <unk> pięćdziesięciu pięciu posłów\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model języka do rozpoznawania ciągów liczb\n",
        "\n",
        "Stwórz listę cyfr: `['zero','jeden','dwa','trzy','cztery','pięć','sześć','siedem','osiem','dziewięć']`\n",
        "\n",
        "Wygeneruj do pliku `digits.txt` 100 linii po 10 losowych cyfr każda:"
      ],
      "metadata": {
        "id": "4BYYx-3_9WBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digits=['zero','jeden','dwa','trzy','cztery','pięć','sześć','siedem','osiem','dziewięć']\n",
        "with open('digits.txt','w') as f:\n",
        "  for l in range(100):\n",
        "    f.write(' '.join([digits[x] for x in randint(0,10,10)])+'\\n')"
      ],
      "metadata": {
        "id": "wfZzL6DLjZak"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 10 digits.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxRsuHrhfD8d",
        "outputId": "cc90bd86-1c42-4676-b44f-5de10dc8d5c9"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "siedem sześć trzy sześć cztery trzy osiem pięć osiem sześć\n",
            "siedem pięć siedem dziewięć cztery pięć dziewięć jeden trzy dwa\n",
            "zero siedem dwa dwa trzy sześć trzy dwa cztery siedem\n",
            "sześć pięć dziewięć siedem dwa dwa sześć dziewięć trzy pięć\n",
            "pięć pięć trzy osiem sześć zero cztery osiem osiem dziewięć\n",
            "siedem dziewięć pięć dziewięć jeden cztery zero trzy dwa dziewięć\n",
            "osiem osiem zero jeden jeden dziewięć dziewięć zero dziewięć jeden\n",
            "pięć cztery jeden trzy dziewięć sześć dwa pięć dwa cztery\n",
            "cztery siedem siedem siedem osiem jeden sześć sześć osiem siedem\n",
            "trzy zero trzy dwa trzy osiem osiem trzy siedem jeden\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zrób z tego pliku model języka `digits.arpa`:"
      ],
      "metadata": {
        "id": "xxUYMvyE9pQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ngram-count -text digits.txt -order 3 -wbdiscount -unk -lm digits.arpa"
      ],
      "metadata": {
        "id": "XFjzjmjqkR59"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sprawdź losowe ciągi z tego modelu - czy odpowiadają temu czego się spodziewamy:"
      ],
      "metadata": {
        "id": "hYWBHxbR9tvY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ngram -lm digits.arpa -unk -gen 10"
      ],
      "metadata": {
        "id": "6LgUppMtktHz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88695434-ee7a-4300-f100-56be3a4adb70"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dwa siedem osiem <unk> cztery trzy\n",
            "dziewięć zero siedem\n",
            "\n",
            "jeden zero trzy pięć sześć trzy\n",
            "siedem sześć jeden\n",
            "pięć osiem <unk> sześć jeden cztery cztery osiem siedem\n",
            "\n",
            "pięć osiem siedem\n",
            "jeden zero jeden <unk> siedem siedem cztery jeden dziewięć\n",
            "cztery sześć trzy trzy osiem cztery pięć sześć cztery sześć jeden dwa <unk> jeden dwa jeden sześć dziewięć cztery\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dekodowanie wygenerowanym modelem języka\n",
        "\n",
        "Użyj `processor.tokenizer.get_vocab()` żeby dostać posortowaną (wg identyfikatorów) listę tokenów w modelu. Zamień separator słów (token `'|'`) na spację:"
      ],
      "metadata": {
        "id": "bTXaRO6h92Fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=[x[0] for x in sorted(processor.tokenizer.get_vocab().items(),key=lambda x:x[1])]\n",
        "print(tokens)\n",
        "tokens[4]=' '\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "EntQElLZk4mA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ede2ca7d-2ab8-4760-9699-8838f0f333a5"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<pad>', '<s>', '</s>', '<unk>', '|', 'e', 'a', 'i', 'o', 'n', 'z', 'r', 'w', 's', 't', 'c', 'y', 'p', 'd', 'k', 'm', 'j', 'u', 'l', 'b', 'g', 'ł', 'h', 'ą', 'ę', 'ż', 'ó', 'ś', 'ć', 'f', 'ń', 'ź', 'v', 'x', 'q', '1']\n",
            "['<pad>', '<s>', '</s>', '<unk>', ' ', 'e', 'a', 'i', 'o', 'n', 'z', 'r', 'w', 's', 't', 'c', 'y', 'p', 'd', 'k', 'm', 'j', 'u', 'l', 'b', 'g', 'ł', 'h', 'ą', 'ę', 'ż', 'ó', 'ś', 'ć', 'f', 'ń', 'ź', 'v', 'x', 'q', '1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Użyj metody `build_ctcdecoder` żeby storzyć dekoder - podaj listę tokenów, plik ARPA oraz parametry `alpha=2.0` oraz `beta=-1.0`:"
      ],
      "metadata": {
        "id": "P3uGDzBw-QKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder=build_ctcdecoder(tokens,'digits.arpa',alpha=2.0,beta=-1.0)"
      ],
      "metadata": {
        "id": "eNMjh-Z-qofG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "469cd84a-d308-4598-cc37-81162c5d2254"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyctcdecode.alphabet:Found entries of length > 1 in alphabet. This is unusual unless style is BPE, but the alphabet was not recognized as BPE type. Is this correct?\n",
            "WARNING:pyctcdecode.language_model:Only 11 unigrams passed as vocabulary. Is this small or artificial data?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Powtórz proces dekodowania, ale zamiast liczyć `torch.argmax` przekaż wynik modelu do decodera. Metoda `decoder.decode` potrzebuje listy w postaci NumPy, więc trzeba ją zamienić używając poleceń: `out.logits.cpu().detach().numpy()`:"
      ],
      "metadata": {
        "id": "rc9IGKnw-iUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trans={}\n",
        "for name,data in tqdm(files.items()):\n",
        "  feats=processor(data,sampling_rate=Fs,return_tensors='pt',padding=True).to('cuda')\n",
        "  out=model(input_values=feats.input_values)\n",
        "  sent=decoder.decode(out.logits.cpu().detach().numpy()[0])\n",
        "  trans[name]=sent"
      ],
      "metadata": {
        "id": "KZKFAL8btO2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e73373-a0ba-478a-88b5-5fab8271ee7e"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:16<00:00,  1.21it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Na samym końcu, wyświetl wyniki i ponownie wylicz WER:"
      ],
      "metadata": {
        "id": "8zhsbw23-8FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h=[]\n",
        "r=[]\n",
        "\n",
        "for name in trans.keys():\n",
        "  print(f'>>{name}')\n",
        "  print(trans[name])\n",
        "  print(ref[name])\n",
        "  print('')\n",
        "\n",
        "  h.append(trans[name])\n",
        "  r.append(ref[name])\n",
        "\n",
        "print(jiwer.compute_measures(r,h))"
      ],
      "metadata": {
        "id": "ggTfviWtt7XY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "outputId": "444706aa-0e03-4ac0-fbb8-fdb5198102b3"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>przyciemnij_oswietlenie\n",
            "przydzemnijoświedlenia\n",
            "przyciemnij oświetlenie\n",
            "\n",
            ">>scisz_muzyke\n",
            "\n",
            "ścisz muzykę\n",
            "\n",
            ">>jarvis_aktywacja\n",
            "carjestaktywacja\n",
            "dżarwis aktywacja\n",
            "\n",
            ">>jarvis_muzyka\n",
            "\n",
            "dżarwis muzyka\n",
            "\n",
            ">>jarvis_v1\n",
            "\n",
            "dżarwis\n",
            "\n",
            ">>wlacz_muzyke\n",
            "\n",
            "włącz muzykę\n",
            "\n",
            ">>poglosnij_muzyke\n",
            "pogłośnimuz\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-128-a785bc2f437f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'>>{name}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'poglosnij_muzyke'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Praca domowa\n",
        "\n",
        "## - na ocenę 3\n",
        "\n",
        "Zastosuj powyższe rozwiązanie na swoich nagraniach i wyświetl wyniki.\n",
        "\n",
        "## - na ocenę 4\n",
        "\n",
        "Dokonaj optymalizacji procesu w celu polepszenia wyniku (pokaż ile się udało poprawić). Spróbuj następujące rzeczy:\n",
        "\n",
        "- różne modele języka\n",
        "- różne parametry dekodera\n",
        "- inne modele z serwisu Huggingface\n",
        "\n",
        "## - na ocenę 5\n",
        "\n",
        "Połącz wynik rozpoznawania mowy z jakimś innym rozwiązaniem albo aplikacją.\n",
        "\n",
        "Na przykład: \n",
        "* zrób prosty kalkulator głosowy\n",
        "* zrób demonstracyjny dialog do zamawiania pizzy\n",
        "* połącz rozwiązanie z jakimś innym modelem NLP\n",
        "\n",
        "Rzuć okiem na https://huggingface.co/tasks oraz https://github.com/jonatasgrosman/huggingsound\n"
      ],
      "metadata": {
        "id": "uD0AFpkr_B8t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "02qdoLF-Aocp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}